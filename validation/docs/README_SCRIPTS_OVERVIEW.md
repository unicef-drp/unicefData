# Validation Scripts - Complete Mapping

**Created:** January 20, 2026  
**Status:** âœ… All 28 production scripts mapped and organized  
**Total Documentation:** 4 comprehensive guides

---

## ğŸ“– Documentation Index

Start with the guide that matches your need:

### ğŸš€ I Want to Get Started Quickly
â†’ Read: **[SCRIPTS_NAVIGATION_GUIDE.md](SCRIPTS_NAVIGATION_GUIDE.md)** (5 min read)
- Quick reference by task
- Common operations with examples
- Learning path for new users

### ğŸ“Š I Want a Visual Overview
â†’ Read: **[DIRECTORY_TREE.md](scripts/DIRECTORY_TREE.md)** (5 min read)
- ASCII tree structure of all folders
- File counts and organization
- Quick reference table

### ğŸ“‹ I Want Complete Inventory
â†’ Read: **[SCRIPTS_STRUCTURE_MAP.md](SCRIPTS_STRUCTURE_MAP.md)** (15 min read)
- All 28 production scripts listed
- What each script does
- Organization best practices
- Maintenance notes

### ğŸ”§ I Want to Understand Data Flow
â†’ Read: **[FUNCTIONAL_DEPENDENCIES.md](scripts/FUNCTIONAL_DEPENDENCIES.md)** (20 min read)
- Execution flow diagrams
- Sampling system explained
- Cache architecture
- Class dependencies

---

## ğŸ¯ Script Organization (Quick Reference)

### 5 Production Folders
```
1. core_validation/       â†’ 5 scripts  Main validation engine
2. orchestration/         â†’ 1 script   Entry point
3. metadata_sync/         â†’ 8 scripts  Data freshness
4. issue_validity/        â†’ 6 scripts  Issue tracking
5. platform_tests/        â†’ 4 scripts  Platform checks
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL PRODUCTION SCRIPTS: 28
```

### Reference Folders
```
_archive/                â†’ 40+ scripts  Legacy/debug (DON'T USE)
diagnostics/             â†’ 0 scripts    Reserved
```

---

## ğŸš€ Quick Start

### Run Validation (10 indicators, all platforms)
```bash
cd C:\GitHub\myados\unicefData-dev\validation
python run_validation.py --limit 10
```

### Run with Stratified Sampling (all 18 dataflows represented)
```bash
python run_validation.py --limit 30 --random-stratified --seed 42
```

### Check Known Issues
```bash
cd scripts/issue_validity
.\run_issue_validity_check.ps1
```

### Update Metadata
```bash
cd scripts/metadata_sync
python orchestrator_metadata.py
```

---

## ğŸ“Š What Each Folder Contains

| Folder | Scripts | Purpose | Use |
|--------|---------|---------|-----|
| **core_validation/** | 5 | Main test engine with caching & sampling | Run validation tests |
| **orchestration/** | 1 | Wrapper and entry point | Coordinate test runs |
| **metadata_sync/** | 8 | Fetch & sync indicator data | Keep data fresh |
| **issue_validity/** | 6 | Track known issues | Detect regressions |
| **platform_tests/** | 4 | Platform-specific quick tests | Quick smoke tests |
| **_archive/** | 40+ | Legacy/debug scripts | Reference only |
| **diagnostics/** | 0 | Reserved for future | Not used yet |

---

## ğŸ”‘ Key Features

### Stratified Sampling
- Groups 645 valid indicators into 18 dataflow prefixes
- Ensures proportional representation
- Minimum 1 per prefix guarantee
- ~18-45 samples for --limit 30

### Intelligent Caching
- Location: `validation/cache/{python,r,stata}/`
- TTL: 7 days per indicator
- Saves ~80% time on repeated runs
- Tracks metadata (timestamp, row count)

### Cross-Language Validation
- Tests Python, R, Stata simultaneously
- Compares outputs across platforms
- Detects platform-specific issues
- Generates unified reports

### Issue Tracking
- Monitors 4 known issues
- Validates fixes across releases
- Generates regression reports
- Tracks issue status over time

---

## ğŸ“ˆ Files Statistics

```
Production:     28 scripts (active, tested, documented)
Reference:      40+ scripts (legacy, debug, examples)
Configuration:  4 documentation files
Folders:        8 total (5 active + 1 archive + 2 reserved)
```

---

## ğŸ“ Understanding the System

### Execution Flow
```
1. User runs: python run_validation.py --limit 30 --random-stratified
2. run_validation.py (wrapper) parses arguments
3. orchestrator_indicator_tests.py (thin pass-through)
4. test_all_indicators_comprehensive.py (core logic)
   â”œâ”€ Load 645 valid indicators
   â”œâ”€ Sample 30-45 (stratified by 18 prefixes)
   â”œâ”€ For each: Test Python â†’ Test R â†’ Test Stata
   â”œâ”€ Check cache, fetch if needed
   â”œâ”€ Compare outputs across platforms
   â””â”€ Generate reports
5. Output: validation/results/{TIMESTAMP}/
```

### Sampling Strategy
```
WITHOUT --random-stratified
â”œâ”€ Sequential selection: first 30 indicators
â””â”€ Sample size: exactly 30

WITH --random-stratified
â”œâ”€ Group by dataflow prefix (CME, COD, DM, etc.)
â”œâ”€ Allocate proportionally: (count/645)*30
â”œâ”€ Enforce minimum 1 per prefix
â””â”€ Sample size: ~36-45 (18 prefixes Ã— min 1 + proportional)
```

### Cache System
```
Check if indicator in cache
â”œâ”€ If YES and < 7 days: Use cached result
â””â”€ If NO or > 7 days: Fetch from API, cache result
```

---

## ğŸ“š Four Documentation Files

You're viewing this index. The three detailed guides are:

1. **SCRIPTS_NAVIGATION_GUIDE.md** - For quick reference
   - Common operations
   - Quick navigation
   - Learning paths

2. **DIRECTORY_TREE.md** - For visual overview
   - ASCII tree structure
   - File organization
   - Quick reference table

3. **SCRIPTS_STRUCTURE_MAP.md** - For complete inventory
   - All 28 scripts described
   - Purpose and features
   - Organization guidelines

4. **FUNCTIONAL_DEPENDENCIES.md** - For data flow understanding
   - Execution flow diagrams
   - Cache architecture
   - Class dependencies

---

## âœ… Verification

After reviewing these docs, you should know:

- [ ] Where each script is located
- [ ] What each folder's purpose is
- [ ] How to run validation (basic and stratified)
- [ ] How stratified sampling works (18 dataflows)
- [ ] Where outputs are saved
- [ ] Where cache is stored
- [ ] How to check known issues
- [ ] How to update metadata
- [ ] Which scripts to use (not legacy ones in _archive)

---

## ğŸ” Finding Things

| Looking For | Go To |
|-------------|-------|
| Visual structure | [DIRECTORY_TREE.md](scripts/DIRECTORY_TREE.md) |
| Script list with descriptions | [SCRIPTS_STRUCTURE_MAP.md](SCRIPTS_STRUCTURE_MAP.md) |
| How scripts connect | [FUNCTIONAL_DEPENDENCIES.md](scripts/FUNCTIONAL_DEPENDENCIES.md) |
| Quick reference by task | [SCRIPTS_NAVIGATION_GUIDE.md](SCRIPTS_NAVIGATION_GUIDE.md) |
| Specific script details | Use Ctrl+F in SCRIPTS_STRUCTURE_MAP.md |
| Flow diagrams | See FUNCTIONAL_DEPENDENCIES.md |
| Common operations | SCRIPTS_NAVIGATION_GUIDE.md or DIRECTORY_TREE.md |

---

## ğŸš€ Next Steps

1. **Try it out:**
   ```bash
   python run_validation.py --limit 10
   ```

2. **Check the output:**
   - Look in `validation/results/` for reports
   - Check `validation/cache/` for cached data

3. **Read more:**
   - Choose a guide based on your needs (see above)
   - Look for specific scripts in SCRIPTS_STRUCTURE_MAP.md

4. **Run advanced validation:**
   ```bash
   python run_validation.py --limit 30 --random-stratified --seed 42
   ```

---

## ğŸ“ Quick Answers

**Q: How many production scripts are there?**  
A: 28 scripts across 5 organized folders

**Q: Where should I run validation?**  
A: `cd validation && python run_validation.py`

**Q: What's stratified sampling?**  
A: Proportional sampling across 18 dataflow prefixes with minimum 1 per group

**Q: Where's the cache?**  
A: `validation/cache/{python,r,stata}/`

**Q: Where are the outputs?**  
A: `validation/results/{TIMESTAMP}/`

**Q: Can I use scripts from _archive/?**  
A: No, those are legacy only. Use scripts in the 5 main folders.

**Q: How do I check if issues are fixed?**  
A: `cd scripts/issue_validity && .\run_issue_validity_check.ps1`

**Q: How do I update metadata?**  
A: `cd scripts/metadata_sync && python orchestrator_metadata.py`

---

**Status:** âœ… Comprehensive mapping complete  
**All 28 production scripts documented and organized**  
**4 detailed guides for different use cases**

